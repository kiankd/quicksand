Results with model LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False) - TRAINED ON CONSENSUS:
             precision    recall  f1-score   support

        com       0.12      0.49      0.19       120
        neg       0.68      0.19      0.29       205
        obj       0.79      0.71      0.75       847
        pos       0.72      0.33      0.46       234

avg / total       0.71      0.55      0.58      1406

[[ 59   5  51   5]
 [ 98  38  66   3]
 [215  12 598  22]
 [116   1  39  78]]

Results with model LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False) - TRAINED ON MAJORITY RULE:
             precision    recall  f1-score   support

        com       0.20      0.07      0.11       120
        neg       0.54      0.38      0.45       205
        obj       0.73      0.88      0.80       847
        pos       0.65      0.55      0.59       234

avg / total       0.64      0.68      0.65      1406

[[  9  16  78  17]
 [  8  78 111   8]
 [ 17  39 746  45]
 [ 11  11  84 128]]



Results with model DummyClassifier(constant=None, random_state=None, strategy='stratified') - TRAINED ON CONSENSUS:
             precision    recall  f1-score   support

        com       0.10      0.43      0.16       120
        neg       0.13      0.06      0.09       205
        obj       0.60      0.46      0.52       847
        pos       0.18      0.10      0.13       234

avg / total       0.42      0.34      0.36      1406

[[ 52   8  48  12]
 [ 85  13  89  18]
 [313  65 391  78]
 [ 78  14 119  23]]

Results with model DummyClassifier(constant=None, random_state=None, strategy='stratified') - TRAINED ON MAJORITY RULE:
             precision    recall  f1-score   support

        com       0.04      0.05      0.05       120
        neg       0.16      0.16      0.16       205
        obj       0.63      0.62      0.63       847
        pos       0.18      0.19      0.19       234

avg / total       0.44      0.43      0.44      1406

[[  6  14  74  26]
 [ 20  33 113  39]
 [ 76 116 525 130]
 [ 33  41 116  44]]


