
Majority settings for everything. 

Confusion matrix = [com, neg, obj, pos]
groundtruth = row, prediction = col
example: there are 78 complicated datapoints that were predicted to be negative. (In train all - test all)

#########################
Train all - Test all
#########################

LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
             precision    recall  f1-score   support

        com      0.200     0.075     0.109       120
        neg      0.542     0.380     0.447       205
        obj      0.732     0.881     0.800       847
        pos      0.646     0.547     0.593       234

avg / total      0.645     0.683     0.655      1406

------------------------------------
[[  9  16  78  17]
 [  8  78 111   8]
 [ 17  39 746  45]
 [ 11  11  84 128]]
------------------------------------
('accuracy', 0.6834992887624467)
------------------------------------

#########################
Train NC - Test NC
#########################

LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
             precision    recall  f1-score   support

        neg      0.600     0.395     0.476       205
        obj      0.787     0.900     0.840       847
        pos      0.705     0.551     0.619       234

avg / total      0.742     0.756     0.742      1286

------------------------------------
[[ 81 114  10]
 [ 41 762  44]
 [ 13  92 129]]
------------------------------------
('accuracy', 0.7558320373250389)
------------------------------------

#########################
Train NC - Test all
#########################

             precision    recall  f1-score   support

        com      0.000     0.000     0.000       120
        neg      0.526     0.395     0.451       205
        obj      0.724     0.900     0.803       847
        pos      0.645     0.551     0.594       234

avg / total      0.620     0.691     0.648      1406

------------------------------------
[[  0  19  84  17]
 [  0  81 114  10]
 [  0  41 762  44]
 [  0  13  92 129]]
------------------------------------
('accuracy', 0.69132290184921763)
------------------------------------

#########################
Train all - Test NC 
#########################

             precision    recall  f1-score   support

        com      0.000     0.000     0.000         0
        neg      0.609     0.380     0.468       205
        obj      0.793     0.881     0.834       847
        pos      0.707     0.547     0.617       234

avg / total      0.748     0.740     0.737      1286

------------------------------------
[[  0   0   0   0]
 [  8  78 111   8]
 [ 17  39 746  45]
 [ 11  11  84 128]]
------------------------------------
('accuracy', 0.74027993779160184)
------------------------------------

(78 + 746 + 128) / (1286 - 8 - 17 - 11) = 76.16%

#########################
Hier - Com/NC -> Obj/NObj - Train all - Test all 
#########################

             precision    recall  f1-score   support

        com      0.185     0.042     0.068       120
        neg      0.500     0.434     0.465       205
        obj      0.746     0.865     0.802       847
        pos      0.571     0.534     0.552       234

avg / total      0.633     0.677     0.648      1406

------------------------------------
[[  5  22  74  19]
 [  6  89  95  15]
 [  8  46 733  60]
 [  8  21  80 125]]
------------------------------------
('accuracy', 0.67709815078236135)
------------------------------------

#########################
Com/NC
#########################

             precision    recall  f1-score   support

        com      0.185     0.042     0.068       120
        ncm      0.917     0.983     0.949      1286

avg / total      0.854     0.903     0.873      1406

------------------------------------
[[   5  115]
 [  22 1264]]
------------------------------------
('accuracy', 0.90256045519203409)
------------------------------------

########################
Com/NC Equalized - Majority Rule
########################

             precision    recall  f1-score   support

        com      0.631     0.158     0.253      1200
        ncm      0.538     0.914     0.677      1286

avg / total      0.583     0.549     0.472      2486

------------------------------------
[[ 190 1010]
 [ 111 1175]]
------------------------------------
('accuracy', 0.54907481898632338)
------------------------------------

########################
Com/NC Equalized - More Complicated
########################

             precision    recall  f1-score   support

        com      0.599     0.472     0.528      1008
        ncm      0.523     0.646     0.578       902

avg / total      0.563     0.554     0.552      1910

------------------------------------
[[476 532]
 [319 583]]
------------------------------------
('accuracy', 0.5544502617801047)
------------------------------------
