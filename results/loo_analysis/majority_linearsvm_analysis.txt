Loading data...
Analyzing results for model linearsvm with label setting majority...


--DATASET STATISTICS--

Gold Label Counts:
  obj - 800
  com - 164
  pos - 213
  neg - 213

Predicted Label Counts:
  obj - 821
  neg - 206
  pos - 219
  com - 144

Topic Counts:
  Companies_and_Products - 1390

Length of Feature Vectors:
  swn_wemb - 1206
  wemb - 201
  unigrams - 1039
  swn - 14
  bigrams - 1235
  total - 3695





--RESULTS WHEN EVALUATING ONLY TWEETS THAT HAD > 0 PERCENT AGREEMENT--
             precision    recall  f1-score   support

        com       0.20      0.18      0.19       164
        neg       0.45      0.43      0.44       213
        obj       0.71      0.73      0.72       800
        pos       0.41      0.42      0.42       213

avg / total       0.56      0.57      0.57      1390


Final F1-Accuracy: 0.565930413263563
Final normal Accuracy: 0.5697841726618705



--RESULTS WHEN EVALUATING ONLY TWEETS THAT HAD > 0.5 PERCENT AGREEMENT--
             precision    recall  f1-score   support

        com       0.09      0.24      0.13        45
        neg       0.49      0.43      0.46       213
        obj       0.77      0.73      0.75       800
        pos       0.45      0.42      0.44       213

avg / total       0.64      0.61      0.62      1271


Final F1-Accuracy: 0.6239885700376019
Final normal Accuracy: 0.6089693154996066



--RESULTS WHEN EVALUATING ONLY TWEETS THAT HAD > 0.79 PERCENT AGREEMENT--
             precision    recall  f1-score   support

        com       0.06      0.33      0.10        15
        neg       0.57      0.50      0.53       136
        obj       0.85      0.77      0.81       623
        pos       0.49      0.51      0.50       132

avg / total       0.74      0.69      0.71       906


Final F1-Accuracy: 0.7092745788701721
Final normal Accuracy: 0.6854304635761589



--RESULTS WHEN EVALUATING ONLY TWEETS THAT HAD > 0.99 PERCENT AGREEMENT--
             precision    recall  f1-score   support

        com       0.03      0.50      0.05         2
        neg       0.59      0.55      0.57        69
        obj       0.90      0.80      0.85       391
        pos       0.51      0.63      0.57        68

avg / total       0.81      0.75      0.77       530


Final F1-Accuracy: 0.7749645867092035
Final normal Accuracy: 0.7471698113207547
